{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c38da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_default_json_conf_file='cnn_emotion4_training_yolo_default.json';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3410f40c-893b-449d-b024-7781e0d76733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import tensorflow as tf\n",
    "#import datetime\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ce46fc-8392-4e0b-a820-3ce426fcc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../library');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d770d436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00acb00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load json conf json file\n",
    "fd = open(os.path.join('./',input_default_json_conf_file));\n",
    "DATA = json.load(fd);\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0f452-3278-49c0-9601-c8a443dbc32b",
   "metadata": {},
   "source": [
    "# Variable globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83c3fa6-dbbb-4644-a12f-e497f971a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed for the random variables\n",
    "seed_number=0;\n",
    "\n",
    "## Dataset \n",
    "dataset_dir    = DATA['dataset_dir'];\n",
    "dataset_name   = DATA['dataset_name'];\n",
    "\n",
    "## Training hyperparameters\n",
    "EPOCAS     = DATA[\"epochs\"];\n",
    "BATCH_SIZE = DATA[\"batch_size\"];\n",
    "\n",
    "## Model of network\n",
    "## 'yolov8n-cls','yolov8s-cls','yolov8m-cls'\n",
    "model_type = DATA[\"model_type\"];\n",
    "\n",
    "## Output\n",
    "output_base_dir = DATA[\"output_base_dir\"];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65186ce7",
   "metadata": {},
   "source": [
    "# Parametros de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1d31d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dataset_base_dir: /media/fernando/Expansion/DATASET/TESE/PATIENT-RECOGNITION/PATIENT-IMAGES/perwi/dataset/train/\n",
      "     dataset_labels_file: labels-emotion4-v1.csv\n",
      "   dataset_base_test_dir: /media/fernando/Expansion/DATASET/TESE/PATIENT-RECOGNITION/PATIENT-IMAGES/perwi/dataset/test/\n",
      "dataset_labels_test_file: labels-emotion4-v1.csv\n",
      "            dataset_name: perwi\n",
      "              model_type: mobilenet_v3\n",
      "                  EPOCAS: 50\n",
      "              BATCH_SIZE: 32\n",
      "         output_base_dir: /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(sys.argv)):\n",
    "    if sys.argv[n]=='--dataset-dir':\n",
    "        dataset_dir=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--dataset-name':\n",
    "        dataset_name=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--model':\n",
    "        model_type=sys.argv[n+1];\n",
    "    elif sys.argv[n]=='--epochs':\n",
    "        EPOCAS=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--batch-size':\n",
    "        BATCH_SIZE=int(sys.argv[n+1]);\n",
    "    elif sys.argv[n]=='--output-dir':\n",
    "        output_base_dir=sys.argv[n+1];\n",
    "        \n",
    "print('        dataset_base_dir:',dataset_dir)\n",
    "print('            dataset_name:',dataset_name)\n",
    "print('              model_type:',model_type)\n",
    "print('                  EPOCAS:',EPOCAS)\n",
    "print('              BATCH_SIZE:',BATCH_SIZE)\n",
    "print('         output_base_dir:',output_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1dee5-778a-4fd9-80de-90620bb33128",
   "metadata": {},
   "source": [
    "# Set seed of random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddef12f-6604-4c71-9473-15f328e954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_number)\n",
    "#tf.keras.utils.set_random_seed(seed_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5189cf-b447-4b0a-b9f3-56f304d6fdde",
   "metadata": {},
   "source": [
    "# Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a786de7-43ac-4597-92eb-d9eee66f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(output_base_dir,dataset_name,'training_validation_holdout',model_type);\n",
    "\n",
    "os.makedirs(output_dir,exist_ok = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf04e51-7a7b-4116-8e1e-04e5f358c5dc",
   "metadata": {},
   "source": [
    "# Create new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d629ba9-d621-4905-a88f-a0730d6c1802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading architecture mobilenet_v3\n",
      "\n",
      "        url: https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\n",
      "target_size: (224, 224)\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1024)              1529968   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 4100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,534,068\n",
      "Trainable params: 4,100\n",
      "Non-trainable params: 1,529,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import BodyEmotion4Lib.lib_yolo_model as myp\n",
    "\n",
    "model, target_size = mpp.create_model(model_type=model_type,load_weights=False,file_of_weight='');\n",
    "\n",
    "\n",
    "#myp.save_model_parameters(model, os.path.join(output_dir,'parameters_stats.m'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1be572-b9c7-422c-9518-53735f9425c7",
   "metadata": {},
   "source": [
    "# Train and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13cd68b8-e1aa-4ef4-af04-e05781f309ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3147 - categorical_accuracy: 0.3810\n",
      "Epoch 1: val_loss improved from inf to 1.16100, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 16s 850ms/step - loss: 1.3147 - categorical_accuracy: 0.3810 - val_loss: 1.1610 - val_categorical_accuracy: 0.4882\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1580 - categorical_accuracy: 0.4742\n",
      "Epoch 2: val_loss improved from 1.16100 to 1.06395, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 651ms/step - loss: 1.1580 - categorical_accuracy: 0.4742 - val_loss: 1.0639 - val_categorical_accuracy: 0.5276\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0456 - categorical_accuracy: 0.5198\n",
      "Epoch 3: val_loss improved from 1.06395 to 1.01001, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 11s 662ms/step - loss: 1.0456 - categorical_accuracy: 0.5198 - val_loss: 1.0100 - val_categorical_accuracy: 0.5669\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9858 - categorical_accuracy: 0.5615\n",
      "Epoch 4: val_loss improved from 1.01001 to 0.97112, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 11s 661ms/step - loss: 0.9858 - categorical_accuracy: 0.5615 - val_loss: 0.9711 - val_categorical_accuracy: 0.5984\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9369 - categorical_accuracy: 0.5853\n",
      "Epoch 5: val_loss improved from 0.97112 to 0.94727, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 11s 659ms/step - loss: 0.9369 - categorical_accuracy: 0.5853 - val_loss: 0.9473 - val_categorical_accuracy: 0.6299\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8839 - categorical_accuracy: 0.6052\n",
      "Epoch 6: val_loss improved from 0.94727 to 0.94288, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 640ms/step - loss: 0.8839 - categorical_accuracy: 0.6052 - val_loss: 0.9429 - val_categorical_accuracy: 0.6457\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8501 - categorical_accuracy: 0.6567\n",
      "Epoch 7: val_loss improved from 0.94288 to 0.92642, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 639ms/step - loss: 0.8501 - categorical_accuracy: 0.6567 - val_loss: 0.9264 - val_categorical_accuracy: 0.6535\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8104 - categorical_accuracy: 0.6627\n",
      "Epoch 8: val_loss improved from 0.92642 to 0.92535, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 644ms/step - loss: 0.8104 - categorical_accuracy: 0.6627 - val_loss: 0.9253 - val_categorical_accuracy: 0.6457\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7907 - categorical_accuracy: 0.6667\n",
      "Epoch 9: val_loss improved from 0.92535 to 0.91393, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 644ms/step - loss: 0.7907 - categorical_accuracy: 0.6667 - val_loss: 0.9139 - val_categorical_accuracy: 0.6457\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7583 - categorical_accuracy: 0.6944\n",
      "Epoch 10: val_loss improved from 0.91393 to 0.90850, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 638ms/step - loss: 0.7583 - categorical_accuracy: 0.6944 - val_loss: 0.9085 - val_categorical_accuracy: 0.6535\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7448 - categorical_accuracy: 0.6944\n",
      "Epoch 11: val_loss improved from 0.90850 to 0.90170, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 640ms/step - loss: 0.7448 - categorical_accuracy: 0.6944 - val_loss: 0.9017 - val_categorical_accuracy: 0.6614\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7406 - categorical_accuracy: 0.7083\n",
      "Epoch 12: val_loss did not improve from 0.90170\n",
      "16/16 [==============================] - 11s 708ms/step - loss: 0.7406 - categorical_accuracy: 0.7083 - val_loss: 0.9068 - val_categorical_accuracy: 0.6457\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7022 - categorical_accuracy: 0.6964\n",
      "Epoch 13: val_loss did not improve from 0.90170\n",
      "16/16 [==============================] - 12s 726ms/step - loss: 0.7022 - categorical_accuracy: 0.6964 - val_loss: 0.9071 - val_categorical_accuracy: 0.6457\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6894 - categorical_accuracy: 0.7401\n",
      "Epoch 14: val_loss improved from 0.90170 to 0.89717, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 12s 743ms/step - loss: 0.6894 - categorical_accuracy: 0.7401 - val_loss: 0.8972 - val_categorical_accuracy: 0.6457\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6711 - categorical_accuracy: 0.7381\n",
      "Epoch 15: val_loss did not improve from 0.89717\n",
      "16/16 [==============================] - 14s 891ms/step - loss: 0.6711 - categorical_accuracy: 0.7381 - val_loss: 0.9020 - val_categorical_accuracy: 0.6220\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6439 - categorical_accuracy: 0.7758\n",
      "Epoch 16: val_loss improved from 0.89717 to 0.88793, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 637ms/step - loss: 0.6439 - categorical_accuracy: 0.7758 - val_loss: 0.8879 - val_categorical_accuracy: 0.6535\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6216 - categorical_accuracy: 0.7778\n",
      "Epoch 17: val_loss improved from 0.88793 to 0.88633, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 640ms/step - loss: 0.6216 - categorical_accuracy: 0.7778 - val_loss: 0.8863 - val_categorical_accuracy: 0.6614\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6120 - categorical_accuracy: 0.7956\n",
      "Epoch 18: val_loss did not improve from 0.88633\n",
      "16/16 [==============================] - 10s 631ms/step - loss: 0.6120 - categorical_accuracy: 0.7956 - val_loss: 0.8912 - val_categorical_accuracy: 0.6535\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5927 - categorical_accuracy: 0.7817\n",
      "Epoch 19: val_loss improved from 0.88633 to 0.88560, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 11s 674ms/step - loss: 0.5927 - categorical_accuracy: 0.7817 - val_loss: 0.8856 - val_categorical_accuracy: 0.6693\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6004 - categorical_accuracy: 0.7778\n",
      "Epoch 20: val_loss did not improve from 0.88560\n",
      "16/16 [==============================] - 10s 633ms/step - loss: 0.6004 - categorical_accuracy: 0.7778 - val_loss: 0.8951 - val_categorical_accuracy: 0.6457\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5990 - categorical_accuracy: 0.7917\n",
      "Epoch 21: val_loss did not improve from 0.88560\n",
      "16/16 [==============================] - 10s 635ms/step - loss: 0.5990 - categorical_accuracy: 0.7917 - val_loss: 0.8886 - val_categorical_accuracy: 0.6614\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5631 - categorical_accuracy: 0.8036\n",
      "Epoch 22: val_loss improved from 0.88560 to 0.88510, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 638ms/step - loss: 0.5631 - categorical_accuracy: 0.8036 - val_loss: 0.8851 - val_categorical_accuracy: 0.6378\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5798 - categorical_accuracy: 0.7758\n",
      "Epoch 23: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 638ms/step - loss: 0.5798 - categorical_accuracy: 0.7758 - val_loss: 0.8910 - val_categorical_accuracy: 0.6457\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5438 - categorical_accuracy: 0.8274\n",
      "Epoch 24: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 11s 651ms/step - loss: 0.5438 - categorical_accuracy: 0.8274 - val_loss: 0.9021 - val_categorical_accuracy: 0.6457\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5406 - categorical_accuracy: 0.8036\n",
      "Epoch 25: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 637ms/step - loss: 0.5406 - categorical_accuracy: 0.8036 - val_loss: 0.8950 - val_categorical_accuracy: 0.6535\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5381 - categorical_accuracy: 0.7976\n",
      "Epoch 26: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 629ms/step - loss: 0.5381 - categorical_accuracy: 0.7976 - val_loss: 0.8986 - val_categorical_accuracy: 0.6614\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5599 - categorical_accuracy: 0.7857\n",
      "Epoch 27: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 636ms/step - loss: 0.5599 - categorical_accuracy: 0.7857 - val_loss: 0.8960 - val_categorical_accuracy: 0.6535\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5411 - categorical_accuracy: 0.7976\n",
      "Epoch 28: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 635ms/step - loss: 0.5411 - categorical_accuracy: 0.7976 - val_loss: 0.8913 - val_categorical_accuracy: 0.6614\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5346 - categorical_accuracy: 0.8075\n",
      "Epoch 29: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 634ms/step - loss: 0.5346 - categorical_accuracy: 0.8075 - val_loss: 0.9034 - val_categorical_accuracy: 0.6378\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5238 - categorical_accuracy: 0.8175\n",
      "Epoch 30: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 638ms/step - loss: 0.5238 - categorical_accuracy: 0.8175 - val_loss: 0.8938 - val_categorical_accuracy: 0.6378\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4898 - categorical_accuracy: 0.8333\n",
      "Epoch 31: val_loss did not improve from 0.88510\n",
      "16/16 [==============================] - 10s 632ms/step - loss: 0.4898 - categorical_accuracy: 0.8333 - val_loss: 0.8890 - val_categorical_accuracy: 0.6457\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4698 - categorical_accuracy: 0.8413\n",
      "Epoch 32: val_loss improved from 0.88510 to 0.88321, saving model to /media/fernando/Expansion/OUTPUTS/DOCTORADO2/cnn_emotion4/perwi/training_validation_holdout/mobilenet_v3/model.h5\n",
      "16/16 [==============================] - 10s 629ms/step - loss: 0.4698 - categorical_accuracy: 0.8413 - val_loss: 0.8832 - val_categorical_accuracy: 0.6535\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4924 - categorical_accuracy: 0.8333\n",
      "Epoch 33: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 635ms/step - loss: 0.4924 - categorical_accuracy: 0.8333 - val_loss: 0.8862 - val_categorical_accuracy: 0.6535\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4930 - categorical_accuracy: 0.8254\n",
      "Epoch 34: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 633ms/step - loss: 0.4930 - categorical_accuracy: 0.8254 - val_loss: 0.8935 - val_categorical_accuracy: 0.6299\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4612 - categorical_accuracy: 0.8472\n",
      "Epoch 35: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 627ms/step - loss: 0.4612 - categorical_accuracy: 0.8472 - val_loss: 0.8937 - val_categorical_accuracy: 0.6614\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4718 - categorical_accuracy: 0.8452\n",
      "Epoch 36: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 632ms/step - loss: 0.4718 - categorical_accuracy: 0.8452 - val_loss: 0.8907 - val_categorical_accuracy: 0.6220\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4606 - categorical_accuracy: 0.8393\n",
      "Epoch 37: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 635ms/step - loss: 0.4606 - categorical_accuracy: 0.8393 - val_loss: 0.8909 - val_categorical_accuracy: 0.6299\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4631 - categorical_accuracy: 0.8532\n",
      "Epoch 38: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 638ms/step - loss: 0.4631 - categorical_accuracy: 0.8532 - val_loss: 0.8901 - val_categorical_accuracy: 0.6220\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4436 - categorical_accuracy: 0.8750\n",
      "Epoch 39: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 631ms/step - loss: 0.4436 - categorical_accuracy: 0.8750 - val_loss: 0.8938 - val_categorical_accuracy: 0.6299\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4321 - categorical_accuracy: 0.8730\n",
      "Epoch 40: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 633ms/step - loss: 0.4321 - categorical_accuracy: 0.8730 - val_loss: 0.8858 - val_categorical_accuracy: 0.6220\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4535 - categorical_accuracy: 0.8472\n",
      "Epoch 41: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 633ms/step - loss: 0.4535 - categorical_accuracy: 0.8472 - val_loss: 0.8929 - val_categorical_accuracy: 0.6299\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4384 - categorical_accuracy: 0.8591\n",
      "Epoch 42: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 656ms/step - loss: 0.4384 - categorical_accuracy: 0.8591 - val_loss: 0.8878 - val_categorical_accuracy: 0.6299\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4361 - categorical_accuracy: 0.8512\n",
      "Epoch 43: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 640ms/step - loss: 0.4361 - categorical_accuracy: 0.8512 - val_loss: 0.8945 - val_categorical_accuracy: 0.6220\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4170 - categorical_accuracy: 0.8552\n",
      "Epoch 44: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 646ms/step - loss: 0.4170 - categorical_accuracy: 0.8552 - val_loss: 0.9023 - val_categorical_accuracy: 0.6220\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4265 - categorical_accuracy: 0.8512\n",
      "Epoch 45: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 639ms/step - loss: 0.4265 - categorical_accuracy: 0.8512 - val_loss: 0.9028 - val_categorical_accuracy: 0.6220\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4392 - categorical_accuracy: 0.8591\n",
      "Epoch 46: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 636ms/step - loss: 0.4392 - categorical_accuracy: 0.8591 - val_loss: 0.9074 - val_categorical_accuracy: 0.6535\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4110 - categorical_accuracy: 0.8829\n",
      "Epoch 47: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 633ms/step - loss: 0.4110 - categorical_accuracy: 0.8829 - val_loss: 0.9039 - val_categorical_accuracy: 0.6378\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3988 - categorical_accuracy: 0.8909\n",
      "Epoch 48: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 640ms/step - loss: 0.3988 - categorical_accuracy: 0.8909 - val_loss: 0.9013 - val_categorical_accuracy: 0.6614\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4190 - categorical_accuracy: 0.8651\n",
      "Epoch 49: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 634ms/step - loss: 0.4190 - categorical_accuracy: 0.8651 - val_loss: 0.9007 - val_categorical_accuracy: 0.6850\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3977 - categorical_accuracy: 0.8889\n",
      "Epoch 50: val_loss did not improve from 0.88321\n",
      "16/16 [==============================] - 10s 631ms/step - loss: 0.3977 - categorical_accuracy: 0.8889 - val_loss: 0.8991 - val_categorical_accuracy: 0.6693\n",
      "max_val_acc 0.6850393414497375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# https://docs.ultralytics.com/modes/train/#train-settings\n",
    "results = model.train(data=dataset_dir, epochs=100, imgsz=224,batch=1,save=True,exist_ok=True)\n",
    "\n",
    "best_model_file=os.path.join('runs','classify','train','weights','best.pt');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083be078-c76e-423a-a538-6e5c6c9cda8c",
   "metadata": {},
   "source": [
    "# Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4f6536-46f0-4c89-b98f-7cb5a4075cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 9s 565ms/step - loss: 0.4786 - categorical_accuracy: 0.8373\n",
      "training {'loss': 0.4786042273044586, 'categorical_accuracy': 0.8373016119003296} \n",
      "\n",
      "\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 0.8832 - categorical_accuracy: 0.6535\n",
      "validation {'loss': 0.8832107782363892, 'categorical_accuracy': 0.6535432934761047} \n",
      "\n",
      "\n",
      "9/9 [==============================] - 7s 774ms/step - loss: 1.0629 - categorical_accuracy: 0.5568\n",
      "testing {'loss': 1.062915563583374, 'categorical_accuracy': 0.5567765831947327} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LOAD BEST MODEL to evaluate the performance of the model\n",
    "model=model.load(best_model_file);\n",
    "\n",
    "\n",
    "data_results=dict();\n",
    "\n",
    "# Evaluate training\n",
    "\n",
    "# Evaluate validation\n",
    "metrics = model.val();\n",
    "print('validation',metrics,\"\\n\\n\");\n",
    "data_results['val_categorical_accuracy']=metrics.top1;\n",
    "\n",
    "# Evaluate testing\n",
    "\n",
    "\n",
    "# final all json\n",
    "with open(os.path.join(output_dir,\"training_data_results.json\"), 'w') as f:\n",
    "    json.dump(data_results, f,indent=4);\n",
    "\n",
    "# final test txt\n",
    "with open(os.path.join(output_dir,\"results_testing.txt\"), 'w') as f: \n",
    "    for key, value in results.items(): \n",
    "        f.write('%s=%s;\\n' % (key, value));\n",
    "\n",
    "#######\n",
    "\n",
    "shutil.move('runs', os.path.join(output_dir,'runs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84facfa9-b65a-4fc8-85c7-025fd02f1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#POSTNAME=str(int(results['accuracy']*100000));\n",
    "#tmp_name='modelo_'+model_type+'_acc'+POSTNAME+'.h5';\n",
    "\n",
    "tmp_name='model_'+model_type+'.h5';\n",
    "\n",
    "os.rename(best_model_file,os.path.join(output_dir,tmp_name));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
